direction: "backward"  # "backward" or "forward"
models_dir: "D:/models/safetensors/input_models/" # directory to cache models locally, can be absolute or relative path
output_dir: "D:/merged_model/"
metric_dir: "./metrics/"
dataset_dir: "./benchmarks/"
layer_swap: false # swap layers between models
tensor_swap: true # swap tensors between models
es_svd: false # use evolutionary strategy with SVD to swap tensors
es_svd_generations: 1 # number of generations for SVD evolutionary strategy
es_svd_sigma: 0.05 # standard deviation for SVD evolutionary strategy
es_norm: false # use evolutionary strategy with normalization to swap tensors
es_norm_generations: 1 # number of generations for norm evolutionary strategy 
es_norm_sigma: 0.005 # standard deviation for evolutionary strategy with normalization
skip_norm: true # skip norm tensor swapping
base_select: false # select base model for merging as model with best (lowest) aggregate rank on dataset metrics
boundary_select: false # swap boundary tensors between models
load_merge_report: false # load & continue the merge report from a previous run
improve_all: "base" # "diversity" "bigram", "exact", "all", "base", or blank (use elitism) TBD: add "any" to ensure at least one metric is improved
samples: 200 # number of dataset samples to evaluate 
base_model_name: jeffmeloy/Qwen2.5-7B-olm-v1.24 # use the base model if base_select is false
max_models: 25 # (tbd) implement code to process this for maximum number of models to merge based on the ones with the best (lowest) aggregate rank
models: # uncomment the models to merge

## Qwen2.5 7B Models ##
#- "jeffmeloy/Qwen2.5-7B-olm-v1.16"
#- "AIDC-AI/Marco-o1"
#- "AlekseyKorshuk/ai-detection-gutenberg-human-v2-formatted-ai-sft-qwen-7b-sft-3epochs"
#- "allura-org/Teleut-7b"
#- "AmberYifan/Qwen2.5-7B-dpo-2k"
#- "AmberYifan/Qwen2.5-7B-dpo-2k-hhrlhf"
#- "Aashraf995/Qwen-Evo-7B"
#- "Azure99/Blossom-V6-7B"
#- "Ba2han/Qwen-2.5-7B-Woonderer-0.1"
#- "beomi/Qwen2.5-7B-Instruct-kowiki-qa"
#- "bespokelabs/Bespoke-Stratos-7B"
#- "brahmairesearch/x1-7B-v0.1"
#- "bugatt/BGLLM"
#- "Bui1dMySea/LongRAG-Qwen2.5-7B-Instruct"
#- "bunnycore/Qandora-2.5-7B"
#- "cooperleong00/Qwen2.5-7B-Instruct-Jailbroken"
#- "DeepGlint-AI/llava-mlcd-qwen2.5-7b"
#- "DrNicefellow/Qwen2.5-7B-O1-Journey-1"
#- "edgerunner-ai/EdgeRunner-Command-Nested"
#- "EVA-UNIT-01/EVA-Qwen2.5-7B-v0.1"
#- "fblgit/cybertron-v4-qw7B-UNAMGS"
#- "FourOhFour/Vapor_v2_7B"
#- "FreedomIntelligence/BlenderLLM"
#- "FreedomIntelligence/HuatuoGPT-o1-7B"
#- "Goekdeniz-Guelmez/Josiefied-Qwen2.5-7B-Instruct-abliterated-v2"
#- "gz987/qwen2.5-7b-cabs-v0.3"
#- "happzy2633/qwen2.5-7b-ins-v3"
#- "Henry94/Qwen2.5-7B-Character"
#- "hotmailuser/QwenSlerp-7B"
#- "huihui-ai/Qwen2.5-7B-Instruct-abliterated-v2" 
#- "HumanLLMs/Human-Like-Qwen2.5-7B-Instruct"
#- "internlm/OREAL-7B-SFT"
#- "internlm/SWE-Fixer-Retriever-7B"
#- "jbjeong91/Qwen2.5_7B_IST_StoryGen_test2"
#- "katanemo/Arch-Function-7B"
#- "Manual-Dataset-Creation-Project/Take-7B"
#- "Manual-Dataset-Creation-Project/Matsu-7B"
#- "Marsouuu/lareneg3Bv2-ECE-PRYMMAL-Martial"
#- "mlfoundations-dev/Bespoke-Stratos-17k-v3"
#- "mlfoundations-dev/hp_ablations_qwen_epoch2"
#- "neopolita/jessi-v0.1-qwen2.5-7b-instruct"
#- "newsbang/Homer-v0.5-Qwen2.5-7B"
#- "nextvalueup/Qwen2.5-7B-Instruct_v3"
#- "nguyentd/FinancialAdvice-Qwen2.5-7B"
#- "nhyha/merge_Qwen2.5-7B-Instruct_20241023_0314"
#- "opencompass/CompassJudger-1-7B-Instruct"
#- "Orion-zhen/Meissa-Qwen2.5-7B-Instruct"
#- "Orion-zhen/Qwen2.5-7B-Gutenberg-KTO"
#- "Orion-zhen/Qwen2.5-7B-Instruct-Uncensored"
#- "qingy2024/UwU-7B-Instruct"
#- "Qwen/Qwen2.5-7B"
#- "Qwen/Qwen2.5-7B-Instruct"
#- "qfq/Qwen2.5-7B-Instruct-20241128-215054"
#- "rombodawg/Rombos-LLM-V2.5-Qwen-7b"
#- "prithivMLmods/Deepthink-Reasoning-7B"
#- "prithivMLmods/Novaeus-Promptist-7B-Instruct"
#- "prithivMLmods/QwQ-MathOct-7B"
#- "scilo/qwen_ft_no_temp"
#- "sethuiyer/Qwen2.5-7B-Anvita"
#- "Siheng99/Qwen2.5-7B-Instruct-SEALONG"
#- "SJTULean/LeanFormalizer_CoT"
#- "SJTULean/LeanFormalizer_PPO"
#- "SJTULean/LeanFormalizer_SFT"
#- "sometimesanotion/KytheraMix-7B-v0.2"
#- "Spestly/Athena-1-7B"
#- "suayptalha/HomerCreativeAnvita-Mix-Qw7B"
#- "tablegpt/TableGPT2-7B"
#- "TIGER-Lab/ScholarCopilot-v1"
#- "thomas-yanxin/XinYuan-Qwen2.5-7B-0917"
#- "Tsunami-th/Tsunami-1.0-7B-Instruct"
#- "tugstugi/Qwen2.5-7B-Instruct-QwQ-v0.1"
#- "win10/Verdandi-Qwen2.5-7B"
#- "winstcha/rewrite-7B-INT4"
#- "Xiaojian9992024/Qwen2.5-THREADRIPPER-Small"
#- "Xiaojian9992024/Qwen2.5-Dyanka-7B-Preview"
#- "xwen-team/Xwen-7B-Chat"
#- "yellowtown/7B-v0.2"
#- "ZeroXClem/Qwen2.5-7B-HomerAnvita-NerdMix"
#- "ZeroXClem/Qwen2.5-7B-HomerCreative-Mix"

# Qwen3-4B based models
- "bespokelabs/qwen3-4b-dabstep-reasoning-108-fixed-reasoning-sharegpt-sft"
- "ertghiu256/deepseek-r1-0528-distilled-qwen3"
- "fakezeta/amoral-Qwen3-4B"
- "Goekdeniz-Guelmez/Josiefied-Qwen3-4B-abliterated-v1"
- "gustavecortal/Piaget-4B"
- "huihui-ai/Huihui-Qwen3-4B-abliterated-v2"
#- "Menlo/Jan-nano" 
- "Menlo/Jan-nano-128k"
- "NiuTrans/GRAM-Qwen3-4B-RewardModel"
- "POLARIS-Project/Polaris-4B-Preview"
- "prithivMLmods/Crux-Qwen3_OpenThinking-4B"
- "prithivMLmods/Qwen3-4B-ft-bf16"
#- "Qwen/Qwen3-4B"
- "radm/prophet-qwen3-4b-sft"
- "Skywork/Skywork-Reward-V2-Qwen3-4B" 
- "Tesslate/UIGEN-T3-4B-Preview"
- "ValiantLabs/Qwen3-4B-Esper3"
- "XformAI-india/Qwen3-4B-medicaldataset"

#- "Cran-May/T.E-8.1"
#- "MadeAgents/Hammer2.0-7b"
#- "Qwen/Qwen2.5-Coder-7B-Instruct"
#- "Qwen/Qwen2.5-Math-7B-Instruct" 
#- "Qwen/Qwen2.5-Coder-7B"
#- "Qwen/Qwen2.5-Math-7B"
#- "OpenBuddy/openbuddy-qwen2.5llamaify-7b-v23.1-200k"
#- "WhiteRabbitNeo/WhiteRabbitNeo-2.5-Qwen-2.5-Coder-7B"
#- "BenevolenceMessiah/Qwen2.5-Coder-7B-3x-Instruct-TIES-v1.1"
#- "BenevolenceMessiah/Qwen2.5-Coder-7B-Chat-Instruct-TIES-v1.2"
#- "Etherll/Qwen2.5-Coder-7B-Instruct-Ties"
#- "THUdyh/Insight-V-Reason"
#- "THUdyh/Insight-V-Summary"
#- "nguyentd/FinancialAdvice-Qwen2.5-7B"
#- "jbjeong91/Qwen2.5_7B_IST_StoryGen_vanilla"
#- "Qwen/Qwen2.5-7B-Instruct"
#- "real-jiakai/Qwen2.5-7B-Instruct-Jiakai"
#- "prithivMLmods/Neumind-Math-7B-Instruct"
#- "prithivMLmods/QwQ-LCoT-7B-Instruct"
#- "prithivMLmods/Qwen-UMLS-7B-Instruct"
#- "ZHIYII/Qwen2.5-7B-Reward"

dataset:
#  "ifeval_sharegpt.json":
#    mode: "bigram_loss"
#    think: false 
#  "bbh_sharegpt.json":
#    mode: "exact_match"
#    think: false
#  "qpqa_sharegpt.json":
#    mode: "bigram_loss"
#    think: false
  "math_lvl5_sharegpt.json":
    mode: "exact_match"
    think: false
#  "mmlupro_sharegpt.json":
#    mode: "exact_match"
#    think: false
#  "truthfulqa_sharegpt.json":
#    mode: "exact_match"
#    think: false
#  "arc_sharegpt.json":
#    mode: "exact_match"
#    think: false
#  "musr_sharegpt.json":
#    mode: "exact_match"
#    think: false
#  "gsm8k_sharegpt.json"
#    mode: "exact_match"
#    think: fasle
#  "reasoning_sharegpt.json":
#    mode: "bigram_loss"
#    think: true
  "longresponse2_sharegpt.json":
    mode: "diversity"
    think: true